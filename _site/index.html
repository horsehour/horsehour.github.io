
	
		
	
		
	
		
		
	
		
	
		
	
		
	
		
		
		<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="shortcut icon" href="/assets/images/horse.png"/><meta name="viewport" content="width=device-width, initial-scale=1"><title> HorseHour</title><meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description. "><link rel="canonical" href="http://localhost:4000/"><link rel="alternate" type="application/rss+xml" title="horsehour" href="http://localhost:4000/feed.xml"><link href='https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|Roboto+Condensed:700&subset=latin' rel='stylesheet' type='text/css'><link rel="stylesheet" href="/assets/css/main.css"><meta property="og:url" content="http://localhost:4000/"><meta property="og:type" content="website"><meta property="og:title" content="HorseHour"><meta property="og:description" content=""><meta property="og:site_name" content="horsehour"><meta property="og:image" content="http://localhost:4000/assets/images/bg.svg"><meta name="twitter:image" content="http://localhost:4000/assets/images/bg.svg"><body><div id="shadow"></div><header class="main-header content-wrapper"> <input type="checkbox" id="menu-checkbox" /><nav class="center-wrapper nav-main"> <a href="/">home</a> <a href="/about/">about me</a> <a href="/articles/">articles</a> <a href="/searchrank/">search and rank</a> <label for="menu-checkbox" class="toggle-button" data-open="☰" data-close="☰" onclick></label></nav></header><main class="content-wrapper"><article class="index-page"><h4><a href="/posts/rl/">Reinforcement Learning</a></h4><ol><li>Book and Research Paper:<ul><li>Sutton, R. S. and Barto, A. G. (1998). Reinforcement learning: An introduction. 1998. A Bradford Book.<li>Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., and Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.<li>Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., et al. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540):529–533.<li>Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M. (2014). Deter- ministic policy gradient algorithms. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 387–395.<li>Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., Schrit- twieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., et al. (2016). Mastering the game of go with deep neural networks and tree search. Nature, 529(7587):484–489.<li>van Hasselt, H. P., Guez, A., Hessel, M., Mnih, V., and Silver, D. (2016). Learning values across many orders of magnitude. In Advances in Neural Information Processing Systems, pages 4287–4295.<li>Salimans, T., Ho, J., Chen, X., and Sutskever, I. (2017). Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864.<li>Pan, Sinno Jialin, and Qiang Yang. “A survey on transfer learning.” IEEE Transactions on knowledge and data engineering 22.10 (2010): 1345-1359.</ul></ol></article><article class="index-page"><h4><a href="/posts/student-college-match/">Student College Matching</a></h4>There are many matching applications in real world, e.g. dating, recruitment of students in universities, and jobs seeking in employment market. The document introduce a simple bilinear matching model, which pictures matching as ranking problem, it can provide online recommendations based on existing data on the preferences from both colleges and students. You can find related code housed on GitHub: https://github.com/horsehour/collegematch.</article><article class="index-page"><h4><a href="/posts/ml-csc/">Machine Learning and Social Choice</a></h4><p>Research papers on computational social choice, machine learning, and programming-related materials.</article><article class="index-page"><h4><a href="/posts/parallel-universes-entropy-and-states-transition/">Parallel Universes, Entropy and States Transition</a></h4><p>对生物的一生进行切片剖解，则每个厚度不一的切片就反映生物在不同时段的状态：人之人生，生物之物态。切片的厚度对应切分的时间长度，也许是一日、一年或百年也未尝不可，全凭切分刀手「若然」的决定。如「若然」对所有同时代的生物一视同仁，选择相同的切分标准，则从更广义的空间来看，单个生物当前的物态与其此前所有物态乃至其他同时期所有生物的当前物态均息息相关。不可否认，每个物态也都存在一定的偶然性。</article></main><footer class="blog-footer content-wrapper"><p>&copy; <span class="full-year"></span> horsehour</footer><script src="/assets/js/scripts.js"></script>
	

